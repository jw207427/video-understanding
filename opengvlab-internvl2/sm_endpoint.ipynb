{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "302862c7-908a-4ba9-b77d-c08ff72c2c11",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d430097-1bd0-4a90-a17c-e5c8355f6603",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker --upgrade --quiet\n",
    "%pip install -U huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703bc4a2-7a17-401e-8063-708aa0c30b72",
   "metadata": {},
   "source": [
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0a8c8b4f-e0d2-49bd-95d5-fcc5a518d34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.djl_inference import DJLModel\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role() # iam role for the endpoint\n",
    "session = sagemaker.session.Session() # sagemaker session for interacting with aws APIs\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "def get_aws_region():\n",
    "    # Get the current AWS region from the default session\n",
    "    session = boto3.session.Session()\n",
    "    return session.region_name\n",
    "\n",
    "region = get_aws_region()\n",
    "prefix=\"Intern-vl2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637771df-7710-4830-9cde-7bed0ccdf6ce",
   "metadata": {},
   "source": [
    "### Download the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a71b428b-47e3-44b0-be33-5e8f110e5e1b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 19 files:   0%|                                 | 0/19 [00:00<?, ?it/s]Downloading 'configuration_internvl_chat.py' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/configuration_internvl_chat.py.2b06ab6f2eddcdb9379c3e4effbbfdda8c538633.incomplete'\n",
      "Downloading 'conversation.py' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/conversation.py.2fe37ad08c18c49fd5a4d7e0aa9be10fbeead22c.incomplete'\n",
      "Downloading '.gitattributes' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/.gitattributes.3ecf72ff46e87246d8fc73fcaf99995ea09063b2.incomplete'\n",
      "Downloading 'examples/image1.jpg' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/examples/image1.jpg.fd9891ef7e00774157a9dcd726b2ea9fa0c5ecff.incomplete'\n",
      "Downloading 'added_tokens.json' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/added_tokens.json.92cb8e68c377d444a75b942a63f65408188bc25b.incomplete'\n",
      "Downloading 'configuration_intern_vit.py' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/configuration_intern_vit.py.ac60112c79abc35627a5b6b58e760c2f78e71839.incomplete'\n",
      "\n",
      "configuration_internvl_chat.py: 100%|██████| 3.80k/3.80k [00:00<00:00, 28.3MB/s]\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/configuration_internvl_chat.py\n",
      "\n",
      ".gitattributes: 100%|██████████████████████| 1.58k/1.58k [00:00<00:00, 16.4MB/s]\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/.gitattributes\n",
      "Downloading 'config.json' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/config.json.a8a614b9ce8229bbabf00cb54a9ba361d78c2257.incomplete'\n",
      "Fetching 19 files:   5%|█▎                       | 1/19 [00:00<00:03,  4.64it/s]\n",
      "conversation.py: 100%|██████████████████████| 15.0k/15.0k [00:00<00:00, 119MB/s]\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/conversation.py\n",
      "\n",
      "examples/image1.jpg:   0%|                          | 0.00/78.1k [00:00<?, ?B/s]\u001b[ADownloading 'README.md' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/README.md.e39c4b683f516aba00078ea23b65307bffc01293.incomplete'\n",
      "\n",
      "\n",
      "added_tokens.json: 100%|███████████████████████| 265/265 [00:00<00:00, 1.92MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/added_tokens.json\n",
      "\n",
      "\n",
      "configuration_intern_vit.py: 100%|█████████| 5.55k/5.55k [00:00<00:00, 59.2MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/configuration_intern_vit.py\n",
      "examples/image1.jpg: 100%|█████████████████| 78.1k/78.1k [00:00<00:00, 1.02MB/s]\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/examples/image1.jpg\n",
      "Downloading 'examples/image2.jpg' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/examples/image2.jpg.25948c75fc4424e29de99aabea4709eb29ff1eb9.incomplete'\n",
      "\n",
      "config.json: 100%|█████████████████████████| 3.68k/3.68k [00:00<00:00, 45.6MB/s]\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/config.json\n",
      "Downloading 'generation_config.json' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/generation_config.json.9aafa20c8d7a52a7eb16fa2a6e20e5048a28724a.incomplete'\n",
      "Downloading 'examples/red-panda.mp4' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/examples/red-panda.mp4.d921c07bb97224d65a37801541d246067f0d506f08723ffa1ad85c217907ccb8.incomplete'\n",
      "\n",
      "README.md: 100%|███████████████████████████| 53.6k/53.6k [00:00<00:00, 10.5MB/s]\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/README.md\n",
      "Fetching 19 files:  11%|██▋                      | 2/19 [00:00<00:02,  6.24it/s]Downloading 'merges.txt' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/merges.txt.8488ce08857fb9abc0dd05fd9f399d6d0234686f.incomplete'\n",
      "Downloading 'model.safetensors' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/model.safetensors.9420916a7fab7d2009f7907cdffa341c9cb6be7c5e0cf4ee193de16fde647dea.incomplete'\n",
      "\n",
      "model.safetensors:   0%|                            | 0.00/1.88G [00:00<?, ?B/s]\u001b[ADownloading 'modeling_intern_vit.py' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/modeling_intern_vit.py.588c3de46ce4748444ddce4a1bb72cb8de74996f.incomplete'\n",
      "\n",
      "\n",
      "generation_config.json: 100%|██████████████████| 117/117 [00:00<00:00, 1.30MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/generation_config.json\n",
      "\n",
      "\n",
      "examples/image2.jpg:   0%|                           | 0.00/126k [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'modeling_internvl_chat.py' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/modeling_internvl_chat.py.92f9848eec843b1a9c421d41724ad9a02d090b39.incomplete'\n",
      "examples/image2.jpg: 100%|███████████████████| 126k/126k [00:00<00:00, 11.6MB/s]\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/examples/image2.jpg\n",
      "Downloading 'preprocessor_config.json' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/preprocessor_config.json.dfd7e50d9d4e67cd679b16b337b419a0c6cfa849.incomplete'\n",
      "\n",
      "\n",
      "merges.txt:   0%|                                   | 0.00/1.67M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "red-panda.mp4:   0%|                                | 0.00/1.87M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "modeling_intern_vit.py: 100%|███████████████| 18.1k/18.1k [00:00<00:00, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/modeling_intern_vit.py\n",
      "Downloading 'special_tokens_map.json' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/special_tokens_map.json.30b3cf2ece59687949bc83892cd1668fcfd3dda4.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "modeling_internvl_chat.py:   0%|                    | 0.00/15.5k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "modeling_internvl_chat.py: 100%|███████████| 15.5k/15.5k [00:00<00:00, 27.7MB/s]\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/modeling_internvl_chat.py\n",
      "red-panda.mp4: 100%|███████████████████████| 1.87M/1.87M [00:00<00:00, 36.1MB/s]\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/examples/red-panda.mp4\n",
      "Fetching 19 files:  53%|████████████▋           | 10/19 [00:00<00:00, 24.47it/s]\n",
      "\n",
      "\n",
      "preprocessor_config.json: 100%|████████████████| 287/287 [00:00<00:00, 3.41MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/preprocessor_config.json\n",
      "Downloading 'tokenizer_config.json' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/tokenizer_config.json.1c0faea9de17f1f1e6e123864ef5db8064655ccd.incomplete'\n",
      "Downloading 'vocab.json' to 'inference/pretrained/InternVL2-1B/.cache/huggingface/download/vocab.json.6bce3a0a3866c4791a74d83d78f6824c3af64ec3.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "special_tokens_map.json: 100%|█████████████████| 498/498 [00:00<00:00, 5.87MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/special_tokens_map.json\n",
      "\n",
      "model.safetensors:   3%|▌                   | 52.4M/1.88G [00:00<00:08, 221MB/s]\u001b[A\n",
      "\n",
      "\n",
      "tokenizer_config.json: 100%|███████████████| 3.02k/3.02k [00:00<00:00, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/tokenizer_config.json\n",
      "\n",
      "\n",
      "\n",
      "vocab.json:   0%|                                   | 0.00/3.38M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "model.safetensors:   4%|▉                   | 83.9M/1.88G [00:00<00:07, 225MB/s]\u001b[A\n",
      "\n",
      "merges.txt: 100%|██████████████████████████| 1.67M/1.67M [00:00<00:00, 4.35MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/merges.txt\n",
      "\n",
      "\n",
      "\n",
      "vocab.json: 100%|██████████████████████████| 3.38M/3.38M [00:00<00:00, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/vocab.json\n",
      "\n",
      "model.safetensors:   6%|█▎                   | 115M/1.88G [00:00<00:07, 238MB/s]\u001b[A\n",
      "model.safetensors:   8%|█▋                   | 147M/1.88G [00:00<00:07, 245MB/s]\u001b[A\n",
      "model.safetensors:  10%|█▉                   | 178M/1.88G [00:00<00:06, 252MB/s]\u001b[A\n",
      "model.safetensors:  11%|██▎                  | 210M/1.88G [00:00<00:06, 259MB/s]\u001b[A\n",
      "model.safetensors:  13%|██▋                  | 241M/1.88G [00:00<00:06, 264MB/s]\u001b[A\n",
      "model.safetensors:  15%|███                  | 273M/1.88G [00:01<00:05, 269MB/s]\u001b[A\n",
      "model.safetensors:  16%|███▍                 | 304M/1.88G [00:01<00:05, 271MB/s]\u001b[A\n",
      "model.safetensors:  18%|███▊                 | 336M/1.88G [00:01<00:05, 270MB/s]\u001b[A\n",
      "model.safetensors:  20%|████                 | 367M/1.88G [00:01<00:05, 272MB/s]\u001b[A\n",
      "model.safetensors:  21%|████▍                | 398M/1.88G [00:01<00:05, 273MB/s]\u001b[A\n",
      "model.safetensors:  23%|████▊                | 430M/1.88G [00:01<00:05, 268MB/s]\u001b[A\n",
      "model.safetensors:  25%|█████▏               | 461M/1.88G [00:01<00:05, 266MB/s]\u001b[A\n",
      "model.safetensors:  26%|█████▌               | 493M/1.88G [00:01<00:05, 265MB/s]\u001b[A\n",
      "model.safetensors:  28%|█████▊               | 524M/1.88G [00:02<00:05, 260MB/s]\u001b[A\n",
      "model.safetensors:  30%|██████▏              | 556M/1.88G [00:02<00:05, 252MB/s]\u001b[A\n",
      "model.safetensors:  31%|██████▌              | 587M/1.88G [00:02<00:05, 257MB/s]\u001b[A\n",
      "model.safetensors:  33%|██████▉              | 619M/1.88G [00:02<00:04, 263MB/s]\u001b[A\n",
      "model.safetensors:  35%|███████▎             | 650M/1.88G [00:02<00:04, 268MB/s]\u001b[A\n",
      "model.safetensors:  36%|███████▋             | 682M/1.88G [00:02<00:04, 273MB/s]\u001b[A\n",
      "model.safetensors:  38%|███████▉             | 713M/1.88G [00:02<00:04, 271MB/s]\u001b[A\n",
      "model.safetensors:  40%|████████▎            | 744M/1.88G [00:02<00:04, 275MB/s]\u001b[A\n",
      "model.safetensors:  41%|████████▋            | 776M/1.88G [00:02<00:04, 272MB/s]\u001b[A\n",
      "model.safetensors:  43%|█████████            | 807M/1.88G [00:03<00:03, 274MB/s]\u001b[A\n",
      "model.safetensors:  45%|█████████▍           | 839M/1.88G [00:03<00:03, 278MB/s]\u001b[A\n",
      "model.safetensors:  46%|█████████▋           | 870M/1.88G [00:03<00:03, 280MB/s]\u001b[A\n",
      "model.safetensors:  48%|██████████           | 902M/1.88G [00:03<00:03, 274MB/s]\u001b[A\n",
      "model.safetensors:  50%|██████████▍          | 933M/1.88G [00:03<00:03, 272MB/s]\u001b[A\n",
      "model.safetensors:  51%|██████████▊          | 965M/1.88G [00:03<00:03, 271MB/s]\u001b[A\n",
      "model.safetensors:  53%|███████████▏         | 996M/1.88G [00:03<00:03, 274MB/s]\u001b[A\n",
      "model.safetensors:  55%|██████████▉         | 1.03G/1.88G [00:03<00:03, 275MB/s]\u001b[A\n",
      "model.safetensors:  56%|███████████▎        | 1.06G/1.88G [00:03<00:02, 273MB/s]\u001b[A\n",
      "model.safetensors:  58%|███████████▌        | 1.09G/1.88G [00:04<00:02, 271MB/s]\u001b[A\n",
      "model.safetensors:  60%|███████████▉        | 1.12G/1.88G [00:04<00:02, 273MB/s]\u001b[A\n",
      "model.safetensors:  61%|████████████▎       | 1.15G/1.88G [00:04<00:02, 275MB/s]\u001b[A\n",
      "model.safetensors:  63%|████████████▋       | 1.18G/1.88G [00:04<00:02, 277MB/s]\u001b[A\n",
      "model.safetensors:  65%|████████████▉       | 1.22G/1.88G [00:04<00:02, 272MB/s]\u001b[A\n",
      "model.safetensors:  67%|█████████████▎      | 1.25G/1.88G [00:04<00:02, 265MB/s]\u001b[A\n",
      "model.safetensors:  68%|█████████████▋      | 1.28G/1.88G [00:04<00:02, 260MB/s]\u001b[A\n",
      "model.safetensors:  70%|█████████████▉      | 1.31G/1.88G [00:04<00:02, 256MB/s]\u001b[A\n",
      "model.safetensors:  72%|██████████████▎     | 1.34G/1.88G [00:05<00:02, 254MB/s]\u001b[A\n",
      "model.safetensors:  73%|██████████████▋     | 1.37G/1.88G [00:05<00:01, 262MB/s]\u001b[A\n",
      "model.safetensors:  75%|██████████████▉     | 1.41G/1.88G [00:05<00:01, 266MB/s]\u001b[A\n",
      "model.safetensors:  77%|███████████████▎    | 1.44G/1.88G [00:05<00:01, 268MB/s]\u001b[A\n",
      "model.safetensors:  78%|███████████████▋    | 1.47G/1.88G [00:05<00:01, 268MB/s]\u001b[A\n",
      "model.safetensors:  80%|███████████████▉    | 1.50G/1.88G [00:05<00:01, 270MB/s]\u001b[A\n",
      "model.safetensors:  82%|████████████████▎   | 1.53G/1.88G [00:05<00:01, 273MB/s]\u001b[A\n",
      "model.safetensors:  83%|████████████████▋   | 1.56G/1.88G [00:05<00:01, 276MB/s]\u001b[A\n",
      "model.safetensors:  85%|████████████████▉   | 1.59G/1.88G [00:06<00:01, 240MB/s]\u001b[A\n",
      "model.safetensors:  87%|█████████████████▎  | 1.63G/1.88G [00:06<00:01, 239MB/s]\u001b[A\n",
      "model.safetensors:  88%|█████████████████▋  | 1.66G/1.88G [00:06<00:00, 248MB/s]\u001b[A\n",
      "model.safetensors:  90%|█████████████████▉  | 1.69G/1.88G [00:06<00:00, 259MB/s]\u001b[A\n",
      "model.safetensors:  92%|██████████████████▎ | 1.72G/1.88G [00:06<00:00, 264MB/s]\u001b[A\n",
      "model.safetensors:  93%|██████████████████▋ | 1.75G/1.88G [00:06<00:00, 270MB/s]\u001b[A\n",
      "model.safetensors:  95%|███████████████████ | 1.78G/1.88G [00:06<00:00, 271MB/s]\u001b[A\n",
      "model.safetensors:  97%|███████████████████▎| 1.81G/1.88G [00:06<00:00, 270MB/s]\u001b[A\n",
      "model.safetensors:  98%|███████████████████▋| 1.85G/1.88G [00:06<00:00, 270MB/s]\u001b[A\n",
      "model.safetensors: 100%|████████████████████| 1.88G/1.88G [00:07<00:00, 264MB/s]\u001b[A\n",
      "Download complete. Moving file to inference/pretrained/InternVL2-1B/model.safetensors\n",
      "Fetching 19 files: 100%|████████████████████████| 19/19 [00:07<00:00,  2.54it/s]\n",
      "/home/ec2-user/SageMaker/video-understanding/opengvlab-internvl2/inference/pretrained/InternVL2-1B\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "#define model_id\n",
    "model_id = \"OpenGVLab/InternVL2-1B\"\n",
    "\n",
    "# clear any existing model artifacts\n",
    "def create_folder(path):\n",
    "    shutil.rmtree(path, ignore_errors=True)\n",
    "    os.makedirs(path)\n",
    "    \n",
    "dir_path = \"inference/pretrained\"\n",
    "create_folder(dir_path)\n",
    "\n",
    "model_name = model_id.split('/')[-1]\n",
    "local_dir = f\"{dir_path}/{model_name}\"\n",
    "\n",
    "!huggingface-cli download --resume-download --local-dir-use-symlinks False {model_id} --local-dir {local_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c3d29-2ead-4968-a236-3a7980aaafff",
   "metadata": {},
   "source": [
    "Push the parameter into `serving.properties` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5942b1e5-13ca-4a91-8d44-27f5b7ee11e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sed -i 's@option.model_id=.*@option.model_id={model_name}@g' inference/serving.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a4f73-5c42-4df5-bd3a-2b4c8ca37fdc",
   "metadata": {},
   "source": [
    "### Upload model folder to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bbbaac4e-4853-49d4-836f-7f5968c33d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4efabe47-69eb-4f3a-bfa6-5708f251e616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\" | xargs rm -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d51b74dd-d08d-4a25-b937-9b9329b147e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 6.2 KiB/6.2 KiB (93.9 KiB/s) with 1 file(s) remaining\r",
      "upload: inference/model.py to s3://sagemaker-us-west-2-376678947624/Intern-vl2/models/model-version-01/model.py\r\n"
     ]
    }
   ],
   "source": [
    "model_s3_uri = f\"s3://{bucket}/{prefix}/models/model-version-01/\"\n",
    "!aws s3 sync ./inference {model_s3_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc28dd-f943-4c63-a660-3879beeea2dd",
   "metadata": {},
   "source": [
    "### Get inference container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6ccafcae-b782-4dd2-ab20-d540185daa31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\", region=session.boto_session.region_name, version=\"0.27.0\"\n",
    ")\n",
    "inference_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "371d4b83-7e77-428b-a547-c40ab290f338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is how we can specify uncompressed model artifacts\n",
    "model_data = {\n",
    "    \"S3DataSource\": {\n",
    "        \"S3Uri\": model_s3_uri,\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None'\n",
    "    }\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ecf510-9b9f-4c98-a308-874dc2d0cbd2",
   "metadata": {},
   "source": [
    "### Create SageMaker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7ed97db9-9578-435d-bc03-572f609cdd1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create your SageMaker Model\n",
    "model = sagemaker.Model(\n",
    "    image_uri=inference_image_uri,\n",
    "    model_data=model_data, \n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c6f73cd1-603e-4c88-922f-b56946afea45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# instance type you will deploy your model to\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(prefix)\n",
    "\n",
    "# deploy your model\n",
    "model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fcd6a9-cc54-4ae1-8d33-377c512c5fe5",
   "metadata": {},
   "source": [
    "### Test Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "1010705f-a95f-4ccb-b505-077e5002abe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924d168-7583-4365-a160-a4f098f9204d",
   "metadata": {},
   "source": [
    "Upload and sync example images to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8e6c7160-49b1-4a29-8723-58c6d87eeced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fa64c523-4c4b-4e87-878d-e4774fc6303b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\" | xargs rm -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "940a9321-119e-4f5a-a4d5-110c3e03cb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples_s3_uri = f\"s3://{bucket}/{prefix}/examples/\"\n",
    "!aws s3 sync ./examples {examples_s3_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66ccf3",
   "metadata": {},
   "source": [
    "### pure-text conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ff5c1ddb-4455-4f13-8e69-0029ca3e747c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 1 μs, total: 3 μs\n",
      "Wall time: 5.25 μs\n",
      "I am an AI assistant whose name is InternVL, developed jointly by Shanghai AI Lab and SenseTime.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "prompt = \"Hello, who are you?\"\n",
    "inputs = {\"prompt\": prompt}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65229b",
   "metadata": {},
   "source": [
    "### single-image single-round conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b7375d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 4.53 μs\n",
      "The image shows a red panda, a small, furry mammal known for its distinctive red and white fur. The red panda is resting on a wooden structure, possibly a platform or a bench, with its head leaning over the edge. The animal has a calm and curious expression, with its eyes looking directly at the camera. The background features a blurred natural setting with greenery, suggesting that the photo was taken in a zoo or a wildlife park.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# single-image single-round conversation (单图单轮对话)\n",
    "prompt = \"<image>\\nPlease describe the image shortly.\"\n",
    "inputs = {\"prompt\": prompt, \"images\":[f\"{examples_s3_uri}examples_image1.jpg\"]}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1f62f",
   "metadata": {},
   "source": [
    "### single-image multi-round conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d4260239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a red panda, a small, furry mammal known for its distinctive red and white fur. The red panda is resting on a wooden structure, possibly a platform or a bench, with its head leaning over the edge. The animal's large, expressive eyes and gentle expression are evident, and it appears to be looking directly at the camera. The background is blurred but suggests an outdoor setting with greenery, indicating that the photo might have been taken in a zoo or a wildlife park.\n",
      "=====\n",
      "\n",
      "In the forest of green,\n",
      "Where the red panda rests,\n",
      "A gentle creature,\n",
      "Its fur a red and white,\n",
      "A sight to behold,\n",
      "A peaceful presence,\n",
      "A symbol of nature's grace.\n"
     ]
    }
   ],
   "source": [
    "# single-image single-round conversation (单图单轮对话)\n",
    "prompt = \"<image>\\nPlease describe the image shortly.\"\n",
    "inputs = {\"prompt\": prompt, \"images\":[f\"{examples_s3_uri}examples_image1.jpg\"], \"parameters\":{\"reset_history\":True}}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))\n",
    "\n",
    "print(\"=====\\n\")\n",
    "\n",
    "prompt = 'Please write a poem according to the image.'\n",
    "\n",
    "inputs = {\"prompt\": prompt}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110ebc8",
   "metadata": {},
   "source": [
    "### multi-image multi-round conversation, combined images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a7001d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 4.77 μs\n",
      "The image depicts a panda cub, which is a species of Asian bear, resting in a natural setting. The cub is positioned in a somewhat relaxed manner, with its head resting on its paws and its front paws holding onto a wooden structure. The cub's fur is predominantly black with white patches, and it has a large, expressive face with large, dark eyes and a small, black nose. The background features lush green foliage, indicating that the cub is in a natural habitat, likely a zoo or wildlife park.\n",
      "\n",
      "The environment is filled with various green plants and trees, suggesting a dense, forested area. The presence of the wooden structure, possibly a part of a wooden fence or platform, adds to the naturalistic setting. The overall scene is serene and peaceful, capturing the natural beauty and tranquility of the panda's habitat.\n",
      "=====\n",
      "\n",
      "The two images depict two different aspects of the same subject, the panda cub. The similarities between the two images include the presence of the panda cub, the natural setting, and the overall serene atmosphere. Both images show the panda cub in a relaxed and peaceful state, resting in a natural habitat.\n",
      "\n",
      "The differences between the two images include the color palette and the background. The first image has a more naturalistic color palette, with green foliage and a wooden structure in the background. The second image has a more artificial color palette, with a more muted color scheme and a more artificial background.\n",
      "\n",
      "Additionally, the first image has a more detailed and intricate background, with a variety of green plants and trees, while the second image has a more simplified and abstract background, with a focus on the panda cub and the wooden structure.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# single-image single-round conversation (单图单轮对话)\n",
    "prompt = \"<image>\\nDescribe the two images in detail.\"\n",
    "inputs = {\n",
    "    \"prompt\": prompt, \n",
    "    \"images\":[f\"{examples_s3_uri}examples_image1.jpg\",\n",
    "              f\"{examples_s3_uri}examples_image2.jpg\",],\n",
    "    \"parameters\":{\"reset_history\":True}\n",
    "}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))\n",
    "print(\"=====\\n\")\n",
    "\n",
    "prompt = 'What are the similarities and differences between these two images.'\n",
    "\n",
    "inputs = {\"prompt\": prompt}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2df2e",
   "metadata": {},
   "source": [
    "### video understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8f5d5142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The red panda is seen hanging upside down from a tree branch.\n",
      "=====\n",
      "\n",
      "In the video, we see two pandas hanging from a tree branch. The panda on the left is black and white, while the one on the right is black and red. They appear to be enjoying the view and seem to be in a relaxed state. The background shows a green forest, which adds to the natural setting of the scene. The camera angle is slightly elevated, giving us a clear view of their movements and expressions. The lighting is bright, and the colors are vivid, making the scene look lively and engaging. Overall, the video captures a peaceful moment between two pandas in their natural habitat.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'What is the red panda doing?'\n",
    "inputs = {\n",
    "    \"prompt\": prompt, \n",
    "    \"video\":f\"{examples_s3_uri}red-panda.mp4\",\n",
    "    \"parameters\":{\"reset_history\":True}\n",
    "}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))\n",
    "print(\"=====\\n\")\n",
    "\n",
    "prompt = 'Describe this video in detail. Don\\'t repeat.'\n",
    "\n",
    "inputs = {\"prompt\": prompt,\n",
    "    \"video\":f\"{examples_s3_uri}red-panda.mp4\",\n",
    "    \"parameters\":{\"reset_history\":True}}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(inputs)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0986d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
